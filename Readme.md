````markdown
# ðŸ“Š Semantic Search for Spreadsheets

This project delivers a **semantic search engine** for Excel workbooks, transforming raw formulas into businessâ€‘readable insights. Users pose naturalâ€‘language queries like:

> â€œShow percentage calculationsâ€  
> â€œFind all revenue formulasâ€  
> â€œWhere are my cost-related metrics?â€

and receive structured JSON responses with detailed explanations of each matching formula.

---

## ðŸ§© Code Components & Parameter Reference

A concise overview of the key functions, their inputs, outputs, and side effectsâ€”as implemented in `sheet-semantic.ipynb`:

### `load_and_parse(paths: List[str]) -> List[Dict[str, Any]]`

- **Inputs**: `paths` â€“ list of spreadsheet file paths.
- **Side Effects**:
  - Populates global maps:
    - `label_map` (nonâ€‘formula cell labels)
    - `formula_map` (raw formula strings)
    - `workbook_raw_map` (openpyxl Workbook with formulas)
    - `workbook_val_map` (openpyxl Workbook with evaluated values)
- **Returns**: `items` â€“ a list of dicts, each containing:
  - `path`, `sheet`, `cell`, `concept`, `formula`, `row_header`, `col_header`, `row_header_col_header`, `description`

### `build_vector_store(items: List[Dict[str, Any]]) -> FAISS`

- **Inputs**: `items` â€“ as returned by `load_and_parse()`
- **Operations**:
  - Extracts `description` texts and corresponding metadata
  - Calls `FAISS.from_texts(texts, embeddings, metadatas=metas)`
- **Output**: prints `Vector store contains {len(texts)} entries.`
- **Returns**: a `FAISS` instance with embedded vectors and metadata

### `resolve_reference(path: str, sheet: str, coord: str) -> str`

- **Purpose**: Convert a cell coordinate into its human-readable label or semantic sub-formula.
- **Logic**:
  1. If present in `formula_map`, returns a wrapped `make_semantic_formula()` call
  2. If present in `label_map`, returns the stored label
  3. Checks left or above neighboring cells for text labels
  4. Falls back to row/column headers via `get_row_header()` / `get_col_header()`
  5. Finally, returns the raw value from `workbook_val_map` or `""`

### `make_semantic_formula(path: str, raw: str, sheet_ctx: str) -> str`

- **Inputs**:
  - `path`: workbook path
  - `raw`: original formula string (e.g. `="Forecast"!B2*0.2`)
  - `sheet_ctx`: current sheet name
- **Process**:
  - Removes `$` signs
  - First replaces **cross-sheet** references via regex + `resolve_reference`
  - Then replaces **same-sheet** references similarly
- **Returns**: a string of the semantic formula, stripped of leading `=`

### `SemanticRetriever.get_relevant_documents(query: str) -> List[Document]`

- **Description**: Wraps FAISS similarity search to produce semantically enriched `Document` objects.
- **Steps**:
  1. Calls `store.similarity_search(query, k=self.k)`
  2. For each result, uses `make_semantic_formula()` to build a humanâ€‘friendly formula
  3. Constructs `Document(page_content, metadata)` for LangChain

### LLM Chain Construction

- **Prompt Template**: `ChatPromptTemplate.from_messages([...])` defines a strict JSON schema with six fields.
- **Document Chain**: `create_stuff_documents_chain(llm=llm, prompt=chat_prompt)`
- **Retrieval QA Chain**: `create_retrieval_chain(retriever=retriever, combine_docs_chain=doc_chain)`

### Execution Flow

1. Define `workbook_paths` and call `load_and_parse(workbook_paths)`
2. Build the FAISS index via `build_vector_store(items)`
3. Instantiate `SemanticRetriever(store=vector_store, k=5)`
4. Assemble the QA chain (`doc_chain`, `qa_chain`)
5. Invoke `qa_chain.invoke({"input": query})` to get `json_answer`

---

## ðŸ“– Design Document

A concise technical narrative covering the core design pillars and the rationale behind implementation decisions.

### 1ï¸âƒ£ Approach to Semantic Understanding

We treat spreadsheet cells not as isolated coordinates but as **semantic units** carrying business meaning.

- **Header-based Concept Inference**: For each formula cell, we extract its row header, column header, and topâ€‘level section label to infer a human concept (e.g. â€œGross Margin (Yr1)â€).
- **Reference Resolution**: Using `resolve_reference()`, raw cell references (e.g. `B5`) are replaced with neighboring labels or header text, enabling phrases like â€œRevenueâ€ or â€œCost of Goods Sold.â€
- **Formula Expansion**: `make_semantic_formula()` recursively replaces both crossâ€‘sheet and sameâ€‘sheet references with resolved labels, producing a semantic string that retains the calculation logic without Excel syntax.

### 2ï¸âƒ£ Handling Business Domain Knowledge

Rather than hardâ€‘coding every financial term, we leverage spreadsheet structure and LLM capabilities:

- **Dynamic Label Mapping**: `label_map` automatically captures any nonâ€‘formula text adjacent to formulas, providing contextual names without a predefined dictionary.
- **Formula Retention**: `formula_map` holds the exact Excel formula, ensuring no loss of computational intent.
- **Value Backâ€‘up**: `workbook_val_map` stores evaluated cell values; used as a fallback when no label or header is available.

This blend of structural parsing and LLM understanding allows the system to work across domains without manual term lists.

### 3ï¸âƒ£ Query Processing & Result Ranking Methodology

1. **Query Ingestion & Expansion**: The user query is passed to Gemini, which enriches it with synonyms and related terms.
2. **Vector Similarity Search**: We embed every itemâ€™s `description` via MiniLM and index in FAISS. At query time, the expanded query is embedded and compared via cosine similarity to retrieve the topâ€‘k most relevant entries.
3. **Ranking Enhancements**: Results are implicitly ranked by vector score. Further refinements include:
   - **Sheet Priority**: Prioritize key sheets (e.g. P&L Statement).
   - **Formula Complexity**: Weight multiâ€‘step calculations more heavily.
   - **Context Depth**: Favor items with richer header context.
4. **LLM Interpretation**: The top results plus metadata are passed to a strict JSON prompt that instructs Gemini to output six fieldsâ€”Concept Name, Location, Formula, Value, Explanation, Business Contextâ€”ensuring consistent, parseable output.

### 4ï¸âƒ£ Technical Architecture & Data Structures

![Detailed Architecture Diagram](Semantic_Search_Architecture.png)

```mermaid
flowchart LR
  subgraph Ingestion
    A[ðŸ“Š Excel Files] --> B[ðŸ§© load_and_parse()]
  end
  subgraph Indexing
    B --> C[ðŸ§  items list with context]
    C --> D[ðŸ§® build_vector_store()]
  end
  subgraph Retrieval
    D --> E[ðŸ” SemanticRetriever]
  end
  subgraph Interpretation
    E --> F[ðŸ§¾ QA Chain] --> G[ðŸ’¬ JSON Response]
  end
```
````

- **Global Maps**:
  - `label_map: Dict[str, str]` â€” maps `"path|sheet!cell"` to header/label text.
  - `formula_map: Dict[str, str]` â€” stores raw formulas.
  - `workbook_raw_map` / `workbook_val_map` â€” hold raw and dataâ€‘only workbooks for reference resolution.
- **Items**: A list of dicts capturing path, sheet, cell, concept, formula, headers, and a combined `description` string used for embedding.

### 5ï¸âƒ£ Performance Considerations & Tradeâ€‘Offs

- **Embedding Caching**: Generating embeddings once per workbook load reduces network calls and latency.
- **Selective Indexing**: Only cells with formulas are indexed, minimizing FAISS memory footprint.
- **Batch LLM Usage**: Topâ€‘k results are combined into a single prompt to Gemini, reducing roundâ€‘trip delays.
- **Parallel Parsing**: For large workbooks, parsing sheets concurrently accelerates initial indexing.

### 6ï¸âƒ£ Challenges Faced & Solutions Implemented

Each challenge is described alongside the thought process and precise code changes:

> **Limited Reference Scope (Sameâ€‘Sheet Only)**
>
> - **Context:** Early `resolve_reference()` handled only sameâ€‘sheet cell references (e.g. `A1`), so crossâ€‘sheet formulas like `='Forecast'!B2` were unresolved.
> - **Insight:** Realized that true workbook semantics span across tabs and require separate detection.
> - **Code Change:** In `make_semantic_formula()`, I inserted a **crossâ€‘sheet regex pass** prior to sameâ€‘sheet logic:
>   ```python
>   for m in re.finditer(r"'([^']+)'!([A-Z]+\d+)|([A-Za-z0-9_]+)!([A-Z]+\d+)", sem):
>       â€¦ resolve_reference(path, sheet_name, cell)
>   ```
>   This guarantees multiâ€‘tab references are captured and replaced correctly.

> **Loss of Calculation Steps (Hardâ€‘Coded Values)**
>
> - **Context:** Recursive expansion sometimes returned final numeric values instead of the chain of operations.
> - **Insight:** Needed to preserve operators and structure while substituting only cell refs.
> - **Code Change:** Stored raw formulas in `formula_map[key]`. In `load_and_parse()`, each `item["description"]` uses that raw `val`, and `make_semantic_formula()` replaces only references, leaving operators intact.

> **Missing Header Context in Embeddings**
>
> - **Context:** FAISS vectors built on `=B5/B6` lacked clarity, leading to poor semantic matches.
> - **Insight:** Embeddings must include humanâ€‘readable context (row, column, section headers).
> - **Code Change:** Enhanced the `description` in each `items.append({...})` to include `row_header`, `col_header`, and `row_header_col_header`:
>   ```python
>   items.append({ â€¦ "description": f"{concept} (sheet={sheet}, cell={cell.coordinate}; row_header={row_hdr}, col_header={col_hdr}, row_header_col_header={row_hdr_col_hdr}): {val}" })
>   ```
>   Vectors now reflect full semantic context.

> **Enforcing Structured JSONâ€‘Only LLM Output**
>
> - **Context:** Early Gemini prompts returned narrative answers, breaking downstream JSON parsing.
> - **Insight:** A strict schema is needed.
> - **Code Change:** Defined a precise `ChatPromptTemplate` listing the six JSON fields and generated responses via `create_stuff_documents_chain()`, which enforces the schema.

---

## ðŸ“ˆ Example Output Payload

```json
{
  {
  "margin_calculations": [
    {
      "Concept Name": "Income Tax (20%)",
      "Location": "P&L Statement!B20",
      "Formula": "((Revenue minus Cost of Goods Sold) minus Total Operating Expenses minus Operating Profit) minus (((Revenue minus Cost of Goods Sold) minus Total Operating Expenses minus Operating Profit) times 20%)",
      "Formula_Explanation": "First, calculate taxable income by subtracting Cost of Goods Sold, Total Operating Expenses, and Operating Profit from Revenue. Then, calculate the income tax by multiplying the taxable income by the tax rate of 20%. Finally, subtract the calculated income tax from the taxable income to arrive at the final Income Tax amount.",
      "Explanation": "This formula calculates income tax, which involves a percentage (20%).",
      "Business Context": "This calculates the company's income tax expense, a key component of the profit and loss statement."
     },
    ]
  }
}
```

```

```
